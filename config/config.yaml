fed_alg: "fedavg"
num_clients: 10
sample_clients: 2

model_name_or_path: "/home/u3011649/Documents/Meta-Llama-3___1-8B/"
llm_type: "meta-llama"
vision_tower_type: clip
vision_tower: "/home/u3011649/Documents/clip/"

mm_projector_type: linear
mm_vision_select_layer: -2
mm_use_im_start_end: False
mm_use_im_patch_token: False

dataset_name: "scienceQA"
data_path: "/home/u3011649/Documents/data/ScienceQA/split_iid_2/"
image_folder: "/home/u3011649/Documents/data/ScienceQA/image"
pad_token_version: "v1"
image_aspect_ratio: pad
group_by_modality_length: True

use_peft: True
lora_enable: True
peft_lora_r: 8
peft_lora_alpha: 32

lr_scheduler_type: "cosine"
learning_rate: 1e-5
num_train_epochs: 10
max_steps: 20
num_rounds: 20
batch_size: 4
model_max_length: 1024
gradient_accumulation_steps: 1
weight_decay: 0.0


load_in_4bit: False
load_in_8bit: False
output_dir: "./output1"
save_steps: 5
save_total_limit: 4
logging_steps: 1
gradient_checkpointing: True

report_to: tensorboard
evaluation_strategy: epoch

dataset_sample: 20000
template: "alpaca"
bf16: True
tf32: True